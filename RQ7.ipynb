{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1583144d-2ed8-47ac-a8e3-f72a4758ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "# Import Requirements\n",
    "import pandas as pd\n",
    "from tqdm import tqdm as tq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pre_processing_posts import pre_processing_posts as pre_posts\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871b81a0-b657-4284-925d-03c02858f1fe",
   "metadata": {},
   "source": [
    "[RQ7] What's the probability that a post receives more than 20% \"likes\" of the number of followers a user has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3968d3cc-e5e0-47e9-83d6-7de752bf3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NaN valued rows\n",
    "df_profiles=pd.read_csv('/home/ec2-user/SageMaker/Data/instagram_profiles.csv',usecols=['sid','followers'],sep='\\t')\n",
    "df_profiles=df_profiles.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b4f1999-45e0-4758-96ce-dad52f3c4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Arguments':#This function takes as input value of number of like(x) and Number of followers(y) for a user\n",
    "'Returns': '1 if the number of likes is greater than 20% of the user else 0 the other way round'\n",
    "def compare_likes_followers(x,y):\n",
    "    if x>(0.2)*y:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a283b78-d126-480a-9165-5f82902d928d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "428it [15:19,  2.15s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i,chunk in tq(enumerate(pd.read_csv('/home/ec2-user/SageMaker/Data/instagram_posts.csv',sep='\\t',usecols=['sid_profile','numbr_likes'],chunksize=100000,keep_default_na=True,na_values=' '))):\n",
    "        chunk=chunk.dropna(how='any')\n",
    "        chunk=chunk.rename(columns={'sid_profile':'sid'})\n",
    "        df_iter=pd.merge(chunk,df_profiles,on='sid')\n",
    "        try:\n",
    "            x=df_iter.apply( lambda row: compare_likes_followers(int(row['numbr_likes']),int(row['followers'])),axis=1)\n",
    "        except:\n",
    "            print('it still does not drop '' ')\n",
    "        sum1=sum1+sum(x) if i!=0 else sum(x)\n",
    "        size=size+len(x) if i!=0 else len(x) \n",
    "        \n",
    "        #print(sum1,size)\n",
    "        \n",
    "print('the probability that a post receives more than 20% \"likes\" of the number of followers a user has is '+str(sum1/size*100)+'%')       \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47248136-0093-4634-ab24-9773cf684011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the probability that a post receives more than 20% \"likes\" of the number of followers a user has is 15.235878494512937%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "% store "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13f20b7-770e-4d0f-bac6-40dd9c44a504",
   "metadata": {},
   "source": [
    "[RQ7.2] Do users usually return to locations? Extract the probability that a user returns to a site after having posted it in the past. Does that probability make sense to you? Explain why or why not.\n",
    "\n",
    "Starting idea is to to get use Locations. csv and Posts.csv simultaneously. \n",
    "Since Locations dataset is small in size, I read the complete Location dataset in one-go. Whereas for the Posts dataset, I read the dataset in multiple chunks.\n",
    "\n",
    "*Approach*:\n",
    "1. While reading the dataset in chunk for Posts I extract the profile id and location_id columns whereas just the 'id' column for the location dataset.\n",
    "\n",
    "2. Now, for each chunk I try to match the Posts['location_id'] with Location['id'] so that I can query location information from the matched location['id'].\n",
    "\n",
    "3. Now each user would have a unique 'Profile Id' and through which I can see how many different locations the user has visited and see if the user went back to the sampe place again.\n",
    "\n",
    "4. For each user, hence I calculate two terms:Freq_places (The places which he has vistited more than once,total_places:no. of unique places he has visited. \n",
    "\n",
    "5. Sum the two variable for all the users and calculate the required probability i.e. probability of users that return back to the places that they have visited once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082a3bf5-6306-4bce-b380-1c398a85b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NaN valued rows #Profiles\n",
    "df_locations=pd.read_csv('/home/ec2-user/SageMaker/Data/instagram_locations.csv',usecols=['id'],sep='\\t')\n",
    "df_locations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9703f7-ba6e-4179-b0c3-05143c02be1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i,chunk in tq(enumerate(pd.read_csv('/home/ec2-user/SageMaker/Data/instagram_posts.csv',sep='\\t',usecols=['profile_id','location_id'],chunksize=100000,keep_default_na=True))):\n",
    "           df_final=pd.merge(chunk,df_locations,left_on='location_id',right_on='id')\n",
    "           df_final=df_final.drop(['id'],axis=1)\n",
    "           x=np.concatenate([x,df_final.values],axis=0) if i!=0 else df_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21ddc6-0c9b-49cc-944e-e86a0377a074",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_id=x.copy()[:,0]\n",
    "location_id=x.copy()[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35fd514-795e-42e1-a218-927a62e1aeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_unique_elements,p_unique_indices,p_indices,p_counts=np.unique(profile_id,return_inverse=True,return_index=True,return_counts=True)\n",
    "l_unique_elements,l_unique_indices,l_indices,l_counts=np.unique(location_id,return_inverse=True,return_index=True,return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889d4da4-a1e3-4673-97ec-d9b99008e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(p_unique_indices):\n",
    "    _,b=np.unique(location_id[p_indices==j],return_counts=True)\n",
    "    freq_places=freq_places+sum(b[b>1]) if i!=0 else sum(b[b>1])\n",
    "    total_places=total_places+len(b) if i!=0 else len(b)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
