{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14dacc3-43aa-4d71-8abf-3eb6082ab251",
   "metadata": {},
   "source": [
    "### Work division\n",
    "#### The work for this notebook is done and compiled by Nemish Murawat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254d50bb-ae5e-4bc8-8e7d-04fa71baedd3",
   "metadata": {},
   "source": [
    "#### Libararies Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1583144d-2ed8-47ac-a8e3-f72a4758ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Requirements\n",
    "import pandas as pd\n",
    "from tqdm import tqdm as tq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pre_processing_posts import pre_processing_posts as pre_posts\n",
    "import datetime\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871b81a0-b657-4284-925d-03c02858f1fe",
   "metadata": {},
   "source": [
    "### RQ7.1 What's the probability that a post receives more than 20% \"likes\" of the number of followers a user has?\n",
    "\n",
    "### *Approach*:\n",
    "#### For this part I would be working with two dataset *Instagram_Profiles.csv* to get followers information and *Instagram_Posts.csv* dataset to get user's likes information.\n",
    "#### Step-1\n",
    ">##### I read the complete dataset of the Instagram_Profiles dataset with columns [sid, followers] as the dataset size is small. \n",
    ">##### I drop rows with NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3968d3cc-e5e0-47e9-83d6-7de752bf3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop NaN valued rows\n",
    "df_profiles=pd.read_csv('/home/ec2-user/SageMaker/Data/instagram_profiles.csv',usecols=['sid','followers'],sep='\\t')\n",
    "df_profiles=df_profiles.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8520607f-1425-4862-b82c-2820e998909c",
   "metadata": {},
   "source": [
    "#### Step-2 \n",
    ">##### I create a function that takes in as input number of likes and number of followers for a user and returns 1 or 0 to highlight those users which follow the constraint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4f1999-45e0-4758-96ce-dad52f3c4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compare_likes_followers(x,y):\n",
    "'''Arguments':#This function takes as input value of number of like(x) and Number of followers(y) for a user\n",
    "\n",
    "'Returns': '1 if the number of likes is greater than 20% of the user else 0 the other way round'''\n",
    "\n",
    "    if x>(0.2)*y:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f070d2-de03-46ca-a5ed-8b9219e22db8",
   "metadata": {},
   "source": [
    "#### Step-3\n",
    "> ##### I iterate over the Instagram_Posts dataset over small-size chunks and just read the 'sid_profile' and 'numbr_likes' columns.\n",
    "> ##### I drop those rowns in chunks which has Nan Values.\n",
    "> ##### I merge df_profile and chunk dataframes on columns ['sid_profiles'] and ['sid'] to get those users which are present in both the datasets.( Removing inconsistencies)\n",
    ">> ##### Given on Kaggle Web page of the datasets that 'sid_profile' is made from the 'sid' of the profiles. Hence used this columns to get a match.\n",
    "> ##### I apply the compare_like_followers function on the merged dataframe on columns['followers' and 'likes'] to get a dataframe which helps me the count of the users which follow the given constraint.\n",
    ">##### Finally, in the next cell I output the recieved result for the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a283b78-d126-480a-9165-5f82902d928d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for i,chunk in tq(enumerate(pd.read_csv('/home/ec2-user/SageMaker/Data/instagram_posts.csv',sep='\\t',usecols=['sid_profile','numbr_likes'],chunksize=100000,keep_default_na=True,na_values=' '))):\n",
    "        chunk=chunk.dropna(how='any')\n",
    "        chunk=chunk.rename(columns={'sid_profile':'sid'})\n",
    "        df_iter=pd.merge(chunk,df_profiles,on='sid')\n",
    "        try:\n",
    "            x=df_iter.apply( lambda row: compare_likes_followers(int(row['numbr_likes']),int(row['followers'])),axis=1)\n",
    "        except:\n",
    "            print('it still does not drop '' ')\n",
    "        sum1=sum1+sum(x) if i!=0 else sum(x)\n",
    "        size=size+len(x) if i!=0 else len(x) \n",
    "        \n",
    "        \n",
    "   \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47248136-0093-4634-ab24-9773cf684011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that a post receives more than 20% \"likes\" of the number of followers a user has is 15.24%\n"
     ]
    }
   ],
   "source": [
    "print('The probability that a post receives more than 20% \"likes\" of the number of followers a user has is '+str(round(sum1*100/size,2))+'%')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13f20b7-770e-4d0f-bac6-40dd9c44a504",
   "metadata": {},
   "source": [
    "### RQ7.2 Do users usually return to locations? Extract the probability that a user returns to a site after having posted it in the past. Does that probability make sense to you? Explain why or why not.\n",
    "\n",
    "##### Starting idea is to to get use Locations. csv and Posts.csv simultaneously. Since Locations dataset is small in size, I read the complete Location dataset in one-go. Whereas for the Posts dataset, I read the dataset in multiple chunks.\n",
    "\n",
    "### *Approach*:\n",
    "> ##### Step-1. While reading the dataset in chunk for Posts I extract the profile id and location_id columns whereas just the 'id' column for the location dataset.\n",
    "> ##### Step-2. Now, for each chunk I try to match the Posts['location_id'] with Location['id'] so that I can query location information from the matched location['id'].\n",
    "> ##### Step-3. Now each user would have a unique 'Profile Id' and through which I can see how many different locations the user has visited and see if the user went back to the sampe place again.\n",
    "> ##### Step-4. Now the final array containing profile_id and location id is quite large and to improve the efficiency.I adopt a following procedure:\n",
    ">> #####        1.I create a string variable using each 'profile_id'-'location_id' (combined) to define a new new variable.       \n",
    ">> #####        2.Now,I pass this variable to a counter object to get the frequencies of the formed string.        \n",
    ">> #####        3.Those string which have counts>1 means that the a particular user have revisited the place.        \n",
    ">> #####        4.Hence I find the sum of all the strings which have more than count=1 and sum of all the counts to estimate the probability.\n",
    "        \n",
    "        \n",
    "#### Assumption:\n",
    " \n",
    "> ##### Every row in *Instagram_location.csv* is distinct.\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082a3bf5-6306-4bce-b380-1c398a85b85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1022658 entries, 0 to 1022657\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count    Dtype\n",
      "---  ------  --------------    -----\n",
      " 0   id      1022658 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 7.8 MB\n"
     ]
    }
   ],
   "source": [
    "#Drop NaN valued rows #Profiles(Step-1)\n",
    "\n",
    "df_locations=pd.read_csv('/home/ec2-user/SageMaker/Data/instagram_locations.csv',usecols=['id'],sep='\\t')\n",
    "df_locations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa9703f7-ba6e-4179-b0c3-05143c02be1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [06:59,  9.76s/it]\n"
     ]
    }
   ],
   "source": [
    "#Step-1 and Step-2\n",
    "for i,chunk in tq(enumerate(pd.read_csv('/home/ec2-user/SageMaker/Data/instagram_posts.csv',sep='\\t',usecols=['profile_id','location_id'],chunksize=1000000,keep_default_na=True))):\n",
    "           df_final=pd.merge(chunk,df_locations,left_on='location_id',right_on='id')\n",
    "           df_final=df_final.drop(['id'],axis=1)\n",
    "           x=np.concatenate([x,df_final.values],axis=0) if i!=0 else df_final.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee21ddc6-0c9b-49cc-944e-e86a0377a074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28063765it [00:53, 525698.56it/s]\n",
      "20074052it [00:05, 3566907.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability that a user returns to a site after having posted it in the past is 38.759571283468205%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Step-3 and Step-4\n",
    "profile_id=x.copy()[:,0]\n",
    "location_id=x.copy()[:,1]\n",
    "z=[]\n",
    "for i,j in tq(enumerate(profile_id)):\n",
    "    z.append(str(j)+'-'+str(location_id[i]))\n",
    "\n",
    "c=Counter(z)\n",
    "count_freq=0\n",
    "for i,j in tq(enumerate(c.values())):\n",
    "    if j>1:\n",
    "        count_freq += j\n",
    "print('The probability that a user returns to a site after having posted it in the past is {}%'.format((count_freq/sum(c.values()))*100))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
